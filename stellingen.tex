\documentclass[a4paper]{article}
\usepackage{a4wide}
\usepackage{palatino}


\author{\Large{Kerstin Bunte}}
\title{Stellingen\\{\large{behorende bij het proefschrift}}\\[.2cm]Adaptive Dissimilarity Measures,\\
Dimension Reduction and Visualization\\[.2cm]{\large{van}}}
\date{}

\begin{document}

\maketitle
\thispagestyle{empty}

\begin{enumerate}
\begin{large}
\item %1
Dissimilarity learning is a powerful concept which gives rise to a variety of different applications.
\item %2
Interpretability, reliability and reproducibility is much more important than highly theoretical and abstract methods.%fancy methods.
% \item %3
% Fancy methods are not used in practice unless they are derived from domain knowledge.
\item Adaptive distance measures increase the flexibility of machine learning techniques and provide important insight 
into the nature of the data and the problem at hand.
% The use of adaptive distance measures in LVQ and other machine learning techniques increases their
% flexibility and provides important insight into the nature of the data and the problem at hand. 
\item %5
What does ``high dimensional data'' mean?\\Asking 3 people might provide you with 10 different answers.
% \item %6
% It is not clear how to measure the dimensionality of a data set.
\item %10
Dimension reduction is generally an ill-posed problem. 
Quality measures to compare different methods are highly desirable. 
\item %11
Supervision might resolve some ambiguities of dimension reduction by clarifying  a data inherent aim. 
\item %7
More benchmark problems are needed for dimensionality reduction.
% \item %8
% Similarities are more accessible than (Euclidean) distances.
% \item %9
% Computational complexity is one of the major bottlenecks.%for real world applications
% \item %4
% Talking to other people bares a lot of potential for collaboration and new projects. 
\item Computer science is no more about computers than astronomy is about telescopes.\begin{flushright}-\,E. W. Edsger Dijkstra\end{flushright}
\item However beautiful the strategy, you should occasionally look at the results.\begin{flushright}-\,Sir Winston Churchill\end{flushright}
\item If you don't know anything about computers, just remember that they are machines that do exactly what you tell them 
but often surprise you in the result.\begin{flushright}-\,Richard Dawkins\end{flushright}%, The Blind Watchmaker (1986), III, p.50
% We can use fancy methods to determine fancy parameters for fancy methods which nobody needs in practice. 
% •Fancy techniques cannot deal with billions of sparse features in real time
% Supervised dimension reduction may resolve parts of the ambiguities. 
% quality of dimension reduction 
% •Availability of (appropriately processed) data is a general problem
% •Preprocessing / metric learning is cool
% •We need parameterless methods or intuitive parameters
% •You cannot learn functions in theory unless you have strong assumptions, but it works in practice (reality is soooo nice J)
\end{large}

\end{enumerate}

\end{document}
